\chapter{Single Systems}
\section{Introduction to Quantum Information}
\dfn{Simplified Description}{Quantum states are represented by vectors with operations represented by matrices. This is sufficient for understanding most quantum algorithms.}
\dfn{General Description}{Quantum states are represented by density matrices with operations represented by superoperators. This definition allows for a more general class of measurements and operations. The simplified description and classical information (including probabilitstic states) are special cases of this definition.}

\section{Classical Information}
Consider a physical system that stores information: let us call it $X$. Assume $X$ can be in one of a finite number of classical states at each moment. Denote this classical state set by $\Sigma$.
\ex{}{
    \begin{itemize}
        \item If $X$ is a bit, then its classical state set is $\Sigma=\{0,1\}$.
        \item If $X$ is a six-sided die, then $\Sigma=\{1,2,3,4,5,6\}$.
        \item If $X$ is a switch on a fan, then $\Sigma=\{\text{high, medium, low, off}\}$.
    \end{itemize}
}

There has to be at least one classical state that the system can be in (which means no empty set) and at least two if it is going to be useful for storing information.

\bigbreak

Often in information processing, our knowledge of the state of $X$ is a bit uncertain; therefore, we can assign probabilities to each of its possible classical states. For example, if $X$ is a bit, then perhaps it is in the state 0 with probability $\frac{3}{4}$ and in the state 1 with probability $\frac{1}{4}$. This is a \textbf{probabilistic state} of $X$.
\ex{Probabilistic states of $X$}{
    \begin{center}
        Pr$(X=0)=\dfrac{3}{4}$ \hspace{1em}and\hspace{1em} Pr$(X=1)=\dfrac{1}{4}$
    \end{center}
}

\newpage

Another succinct way to represent this is by a \textbf{column vector} (probability vector):
\ex{Column vector of $X$}{
    \begin{equation*}
        \begin{pmatrix}
        \dfrac{3}{4} \\[1em]
        \dfrac{1}{4}
        \end{pmatrix}
        \qquad
        \begin{aligned}
        \text{entry corresponding to 0} \\[1em]
        \text{entry corresponding to 1}
        \end{aligned}
    \end{equation*}
}

\remark{All entries of a classical probabilistic vector are nonnegative real numbers and sum to 1.}

\subsection{Dirac notation (pt.1)}
Let $\Sigma$ be any classical state set, and assume the elements of $\Sigma$ have been placed in correspondence with the integers $1,\cdots,|\Sigma|$.

\bigbreak

We denote $\ket{a}$ (``ket a'') as the column vector having a 1 in the entry corresponding to $a\in\Sigma$, with 0 for all other entries.

\ex{}{
If $\Sigma=\{0,1\}$, then $\ket{0}=
\begin{pmatrix}
1 \\
0
\end{pmatrix}
$ and $\ket{1}=
\begin{pmatrix}
0 \\
1
\end{pmatrix}$. \\
If $\Sigma=\{\clubsuit,\diamondsuit,\heartsuit,\spadesuit\}$ and we assume this ordering, this yields:
\begin{itemize}
\item[-] $\ket{\clubsuit}=
\begin{pmatrix}
1 \\
0 \\
0 \\
0
\end{pmatrix}$
\item[-] $\ket{\diamondsuit}=
\begin{pmatrix}
0 \\
1 \\
0 \\
0
\end{pmatrix}$
\item[-] $\ket{\heartsuit}=
\begin{pmatrix}
0 \\
0 \\
1 \\
0
\end{pmatrix}$
\item[-] $\ket{\spadesuit}=
\begin{pmatrix}
0 \\
0 \\
0 \\
1
\end{pmatrix}$
\end{itemize}
}

\begin{note}
Vectors of this form are called standard basis vectors. Every vector can be expressed uniquely as a linear combination of standard basis vectors. For example,
$\begin{pmatrix}
\frac{3}{4} \\[0.5em]
\frac{1}{4}
\end{pmatrix}
=\dfrac{3}{4}\ket{0}+\dfrac{1}{4}\ket{1}$.
\end{note}

If you happen to measure the state of $X$ being $a\in\Sigma$, then Pr$(X=a)=1$. Measuring $X$ selects a transition, chosen at random. For example, using $\dfrac{3}{4}\ket{0}+\dfrac{1}{4}\ket{1}$, $X$ can be measured as $\ket{0}$ with probability $\dfrac{3}{4}$ or $\ket{1}$ with probability $\dfrac{1}{4}$.

\subsection{Deterministic operations}
There's no element of chance when a deterministic operation is performed, so there's no randomness or uncertainty involved.

\bigbreak

Every function $f:\Sigma\rightarrow\Sigma$ describes a deterministic operation that transforms the classical state $a$ into $f(a)$, for each $a\in\Sigma$.

\dfn{Matrix Representation}{
    Given any function $f:\Sigma\rightarrow\Sigma$, there is a unique matrix $M$ satisfying $M\ket{a}=\ket{f(a)}$ for every $a\in\Sigma$. This matrix has exactly one 1 in each column, and 0 for all other entries:
    \begin{equation*}
        M(b,a)=
        \begin{cases}
            1 & b=f(a) \\
            0 & b\neq f(a)
        \end{cases}
    \end{equation*}}

\ex{}{
For $\Sigma=\{0,1\}$, there are four functions of the form $f:\Sigma\rightarrow\Sigma$:

\begin{table}[H]
\captionsetup{justification=centering}
\parbox{.225\linewidth}{
\centering
\begin{tabular}{c|c}
    $a$ & $f_1(a)$ \\ 
    \hline 
    0 & 0 \\ 
    1 & 0 \\ 
\end{tabular}
\caption*{
zero function\\
$f_1(0)=0$\\
$f_1(1)=0$}
}
\hfill
\parbox{.225\linewidth}{
\centering
\begin{tabular}{c|c}
    $a$ & $f_2(a)$ \\ 
    \hline 
    0 & 0 \\ 
    1 & 1 \\ 
\end{tabular}
\caption*{
identity function\\
$f_2(0)=0$\\
$f_2(1)=1$}
}
\hfill
\parbox{.225\linewidth}{
\centering
\begin{tabular}{c|c}
    $a$ & $f_3(a)$ \\ 
    \hline 
    0 & 1 \\ 
    1 & 0 \\ 
\end{tabular} 
\caption*{
NOT function\\
$f_3(0)=1$\\
$f_3(1)=0$}
}
\hfill
\parbox{.225\linewidth}{
\centering
\begin{tabular}{c|c}
    $a$ & $f_4(a)$ \\ 
    \hline 
    0 & 1 \\ 
    1 & 1 \\ 
\end{tabular} 
\caption*{
one function\\
$f_4(0)=1$\\
$f_4(1)=1$}
}
\end{table}

Here are the matrices corresponding to these functions:

\begin{table}[H]
\parbox{.225\linewidth}{
\centering
$M_1=\begin{pmatrix}
    1 & 1 \\ 
    0 & 0
\end{pmatrix}$
}
\hfill
\parbox{.225\linewidth}{
\centering
$M_2=\begin{pmatrix}
    1 & 0 \\ 
    0 & 1
\end{pmatrix}$
}
\hfill
\parbox{.225\linewidth}{
\centering
$M_3=\begin{pmatrix}
    0 & 1 \\ 
    1 & 0
\end{pmatrix}$
}
\hfill
\parbox{.225\linewidth}{
\centering
$M_4=\begin{pmatrix}
    0 & 0 \\ 
    1 & 1
\end{pmatrix}$
}
\end{table}
}

\begin{note}
    Recall that the 0 state is represented by the column vector
    $\begin{pmatrix}
        0 \\
        1
    \end{pmatrix}$.
    and the 1 state is represented by the column vector
    $\begin{pmatrix}
        1 \\
        0
    \end{pmatrix}$.
\end{note}

\subsection{Dirac notation (pt.2)}
Let $\Sigma$ be any classical state set, and assume the elements of $\Sigma$ have been placed in correspondence with the integers $1,\cdots,|\Sigma|$.

\bigbreak

We denote by $\bra{a}$ (``bra a'') the row vector having a 1 in the entry corresponding to $a\in\Sigma$, with 0 for all other entries.

\bigbreak

If $\Sigma=\{0,1\}$, then $\bra{0}=
\begin{pmatrix}
    1 & 0
\end{pmatrix}$
and $\bra{1}=
\begin{pmatrix}
    0 & 1
\end{pmatrix}$.

\newpage

Multiplying a row vector to a column vector yields a scalar:
\begin{center}
    $\begin{pmatrix}
        * & * & \cdots & *
    \end{pmatrix}
    \begin{pmatrix}
        * \\
        * \\
        \vdots \\
        *
    \end{pmatrix}
    =
    (*)$
    \bigbreak
    $
    \braket{a|b}=
    \begin{cases}
    1 & a=b \\
    0 & a\neq b
    \end{cases}$
\end{center}

Multiplying a column vector to a row vector yields a matrix:
\begin{center}
    $\begin{pmatrix}
        * \\
        * \\
        \vdots \\
        *
    \end{pmatrix}
        \begin{pmatrix}
        * & * & \cdots & *
    \end{pmatrix}
    =
    \begin{pmatrix}
        * & * & \cdots & * \\
        * & * & \cdots & * \\
        \vdots & \vdots & \ddots & \vdots \\
        * & * & \cdots & *
    \end{pmatrix}$
\end{center}

In general, $\ket{a}\hspace{-0.3em}\bra{b}$ has a 1 in the $(a,b)$-entry and 0 for all other entries.

\bigbreak

The matrix may now be expressed as $M=\sum\limits_{b\in\sum}\ket{f(b)}\hspace{-0.3em}\bra{b}$.

\subsection{Probabilistic operations}
Probabilistic operations are classical operations that may introduce randomness or uncertainty. They are described by stochastic matrices:
\begin{itemize}
    \item All entries are nonnegative real numbers.
    \item All columns sum to 1.
\end{itemize}

\ex{Probabilistic operation on a bit}{
    \begin{itemize}
        \item If the classical state is 0, then do nothing.
        \item If the classical state is 1, then flip the bit with probability $\dfrac{1}{2}$.
    \end{itemize}
    Here it is visualized as a matrix:
    \begin{center}
        $\begin{pmatrix}
        1 & \frac{1}{2} \\[0.5em]
        0 & \frac{1}{2}
        \end{pmatrix}
        =
        \dfrac{1}{2}
        \begin{pmatrix}
        1 & 0 \\
        1 & 0
        \end{pmatrix}
        +
        \dfrac{1}{2}
        \begin{pmatrix}
        1 & 0 \\
        0 & 1
        \end{pmatrix}$
    \end{center}
}

\subsection{Composing operations}
\ex{}{
    Suppose $X$ is a system and $M_1,\cdots,M_n$ are stochastic matrices representing probabilistic operations on $X$. Applying the first probabilistic operation to the probability vecotr $v$, then applying the second probabilistic operation to the result yields this vector:
    \begin{center}
        $M_2(M_1v)=(M_2M_1)v$
    \end{center}
    The probabilistic operation obtained by composing the first and second probabilistic operations is represented by the matrix product $M_2M_1$. Composing the probabilistic operations represented by the matrices $M_1,\cdots,M_n$ is represented by the matrix product:
    \begin{center}
        $M_n\cdots M_2M_1$
    \end{center}
    }

\remark{The order is important: matrix multiplication is \textbf{not} commutative.}

\section{Quantum Information}
A quantum state of a system is represented by a column vector whose indices are places in correspondence with the classical states of that system:
\begin{itemize}
    \item The entries are complex numbers.
    \item The sum of the absolute values squared of the entries is 1.
\end{itemize}
The Euclidean norm (or $\ell^2$-norm) for vectors with complex entries is defined as:
\begin{equation*}
    v=
    \begin{pmatrix}
        \alpha_1 \\
        \vdots \\
        \alpha_n
    \end{pmatrix}
    \Rightarrow
    ||v||=\sqrt{\sum\limits_{k=1}^n|\alpha_k|^2}
\end{equation*}
Quantum state vectors are therefore unit vectors with respect to this norm.

\ex{Qubit states}{
    \begin{itemize}
        \item Standard basis states: $\ket{0}$ and $\ket{1}$
        \item Plus/minus states:
        \begin{center}
            $\ket{+}=\dfrac{1}{\sqrt{2}}\ket{0}+\dfrac{1}{\sqrt{2}}\ket{1}$ and $\ket{-}=\dfrac{1}{\sqrt{2}}\ket{0}-\dfrac{1}{\sqrt{2}}\ket{1}$
        \end{center}
        \item $\dfrac{1+2i}{3}\ket{0}-\dfrac{2}{3}\ket{1}$ (random state)
    \end{itemize}
}

\subsection{Dirac notation (pt.3)}
The Dirac notation can be used for arbitrary vectors: any name can be used in place of a classical state.
\ex{}{
    \begin{itemize}
        \item Ket = $\ket{\psi}$ = column vectors
        \item Bra = $\bra{\psi}$ = row vectors
    \end{itemize}
}

The notation $\ket{\psi}$ (psi) is commonly used to refer to an arbitrary vector:
\ex{}{
    \begin{itemize}
        \item $\ket{\psi}=\dfrac{1+2i}{3}\ket{0}-\dfrac{2}{3}\ket{1}=
        \begin{pmatrix}
            \dfrac{1+2i}{3} \\[1em]
            -\dfrac{2}{3}
        \end{pmatrix}$
        \item $\bra{\psi}=\dfrac{1-2i}{3}\bra{0}-\dfrac{2}{3}\bra{1}=
        \begin{pmatrix}
            \dfrac{1-2i}{3} & -\dfrac{2}{3}
        \end{pmatrix}$
    \end{itemize}
}

\newpage

\begin{note}
    For any column vector $\ket{\psi}$, the corresponding row vector is $\bra{\psi}=\ket{\psi}^\dagger$ (psi dagger), where $\dagger$ denotes the conjugate transpose. The notation $\ket{\psi}^\dagger$ means to take the transpose of $\ket{\psi}$ and then take the complex conjugate of each entry, or vice versa; the order does not matter.
\end{note}

\subsection{Measuring quantum states}
Things to note about measuring quantum states:
\begin{itemize}
    \item The possible outcomes are the classical states.
    \item The probability for each classical state to be the outcome is the absolute value squared of the corresponding quantum state vector entry.
\end{itemize}

Measuring the quantum state $\ket{0}$ gives the outcome 0 with certainty, and measuring the quantum state $\ket{1}$ gives the outcome 1 with certainty.

\ex{}{
    Measuring the quantum state $\ket{+}=\dfrac{1}{\sqrt{2}}\ket{0}+\dfrac{1}{\sqrt{2}}\ket{1}$ yields an outcome as follows:
    \begin{center}
        Pr(outcome is 0) = $|\dfrac{1}{\sqrt{2}}|^2=\dfrac{1}{2}$ \hspace{3em} Pr(outcome is 1) = $|\dfrac{1}{\sqrt{2}}|^2=\dfrac{1}{2}$
    \end{center}
}

Measuring a system changes its quantum state: if we obtain the classical state $\alpha$, then the quantum state of the system is $\ket{\alpha}$.

\ex{}{
    The system $\dfrac{1+2i}{3}\ket{0}-\dfrac{2}{3}\ket{1}$ has a probability of $\dfrac{5}{9}$ to ``collapse'' to the quantum state $\ket{0}$ and a probability of $\dfrac{4}{9}$ to ``collapse'' to the quantum state $\ket{1}$.
}

\subsection{Unitary operations}
Operations on quantum state vectors are represented by unitary matrices.

\bigbreak
A square matrix $\mathcal{U}$ having complex entries is unitary if it satisfies the equalities
\begin{equation*}
    \mathcal{U}^\dagger\mathcal{U}=(\mathbbm{1}\text{ or }I_n)=\mathcal{U}\mathcal{U}^\dagger
\end{equation*}
where $\mathcal{U}^\dagger$ is the conjugate transpose of $\mathcal{U}$ and $\mathbbm{1}$ is the identity matrix.

\bigbreak

The condition that an $n\times n$ matrix $\mathcal{U}$ is unitary is equivalent to $||\mathcal{U}v||=||v||$ for every $n$-dimensional column vector $v$ with complex number entries.

\bigbreak

If $v$ is the quantum state vector, then $\mathcal{U}v$ is also a quantum state vector.

\newpage

\subsection{Qubit unitary operations}

\ex{Pauli operations}{
    Pauli operators are ones represented by the Pauli matrices:
    \begin{table}[H]
        \captionsetup{justification=centering}
        \parbox{.225\linewidth}{
        \centering
        $\mathbbm{1}=
        \begin{pmatrix}
        1 & 0 \\
        0 & 1
        \end{pmatrix}$
        }
        \hfill
        \parbox{.225\linewidth}{
        \centering
        $\sigma_x=
        \begin{pmatrix}
        0 & 1 \\
        1 & 0
        \end{pmatrix}$
        }
        \hfill
        \parbox{.225\linewidth}{
        \centering
        $\sigma_y=
        \begin{pmatrix}
        0 & -i \\
        i & 0
        \end{pmatrix}$
        }
        \hfill
        \parbox{.225\linewidth}{
        \centering
        $\sigma_z=
        \begin{pmatrix}
        1 & 0 \\
        0 & -1
        \end{pmatrix}$
        }
    \end{table}
    
    They also happen to be equal to their conjugate transposes, so they are also Hermitian matrices. \\
    Common alternative notations: $\mathcal{X}=\sigma_x$, $\mathcal{Y}=\sigma_y$, $\mathcal{Z}=\sigma_z$

    \bigbreak

    The operation $\sigma_x$ is also called a bit flip (or a NOT operation) and the $\sigma_z$ operation is called a phase flip:
    \begin{center}
    \hspace{-1em}$\sigma_x\ket{0}=\ket{1}$ \hspace{3em} $\sigma_z\ket{0}=\ket{0}$ \\
    $\sigma_x\ket{1}=\ket{0}$ \hspace{3em} $\sigma_z\ket{1}=-\ket{1}$
    \end{center}
}

\ex{Hadamard operation}{
    The Hadamard operation is represented by this matrix:
    \begin{equation*}
    \mathcal{H}=
    \begin{pmatrix}
    \dfrac{1}{\sqrt{2}} & \dfrac{1}{\sqrt{2}} \\[1em]
    \dfrac{1}{\sqrt{2}} & -\dfrac{1}{\sqrt{2}}
    \end{pmatrix}
    \end{equation*}
    
    Checking that $\mathcal{H}$ is indeed unitary:
    \begin{equation*}
    \begin{pmatrix}
    \dfrac{1}{\sqrt{2}} & \dfrac{1}{\sqrt{2}} \\[1em]
    \dfrac{1}{\sqrt{2}} & -\dfrac{1}{\sqrt{2}}
    \end{pmatrix}^\dagger
    \begin{pmatrix}
    \dfrac{1}{\sqrt{2}} & \dfrac{1}{\sqrt{2}} \\[1em]
    \dfrac{1}{\sqrt{2}} & -\dfrac{1}{\sqrt{2}}
    \end{pmatrix}=
    \begin{pmatrix}
    \dfrac{1}{\sqrt{2}} & \dfrac{1}{\sqrt{2}} \\[1em]
    \dfrac{1}{\sqrt{2}} & -\dfrac{1}{\sqrt{2}}
    \end{pmatrix}
    \begin{pmatrix}
    \dfrac{1}{\sqrt{2}} & \dfrac{1}{\sqrt{2}} \\[1em]
    \dfrac{1}{\sqrt{2}} & -\dfrac{1}{\sqrt{2}}
    \end{pmatrix}=
    \begin{pmatrix}
    1 & 0 \\
    0 & 1
    \end{pmatrix}
    \end{equation*}
    
    Seeing that the conjugate transpose is equal to itself, it also happens to be a Hermitian matrix.
}

\ex{Phase operations}{
    A phase operation is one described by this matrix:
    \begin{equation*}
    \mathcal{P}_\theta=
    \begin{pmatrix}
    1 & 0 \\
    0 & e^{i\theta}
    \end{pmatrix}
    \end{equation*}
    with $\theta$ being any real number.
    
    \bigbreak
    
    The operations
    \begin{center}
    $\mathcal{S}=\mathcal{P}_{\frac{\pi}{2}}=
    \begin{pmatrix}
    1 & 0 \\
    0 & i
    \end{pmatrix}$
        and 
    $\mathcal{T}=\mathcal{P}_{\frac{\pi}{4}}=
    \begin{pmatrix}
    1 & 0 \\
    0 & \dfrac{1+i}{\sqrt{2}}
    \end{pmatrix}$
    \end{center}
    are important examples.
}

\subsection{Composing unitary operations}
Composition of unitary operations are represented by matrix multiplication (similar to the probabilistic setting), i.e., you can compute the action of a sequence of unitary operations just by multiplying the matrices together, which will end up being a single unitary matrix.